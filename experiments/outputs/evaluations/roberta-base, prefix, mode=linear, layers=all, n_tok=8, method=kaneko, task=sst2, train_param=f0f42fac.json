{
   "model_config": {
      "model_name": "roberta-base",
      "model_type": "prefix",
      "debias_method": "kaneko",
      "prefix_mode": "linear",
      "prefix_layers": "all",
      "n_prefix_tokens": 8,
      "downstream_task": "sst2",
      "head_size": 1,
      "epochs": 1,
      "batch_size": 32,
      "lr": 2e-06,
      "num_warmup_steps": 40,
      "seed": 42
   },
   "evaluations": {
      "seat": {
         "6": {
            "effect_size": -0.0865,
            "p_val": 0.6867
         },
         "7": {
            "effect_size": -0.338,
            "p_val": 0.9791
         },
         "8": {
            "effect_size": -0.1158,
            "p_val": 0.7277
         },
         "stereo": {
            "effect_size": 0.2431,
            "p_val": 0.0205
         }
      },
      "lpbs": {
         "adjectives": {
            "bias_score": 0.7813,
            "bias_score_std": 0.6137
         },
         "kaneko_stereotypes": {
            "bias_score": 0.8562,
            "bias_score_std": 0.6661
         },
         "occupations": {
            "bias_score": 0.8613,
            "bias_score_std": 0.6547
         }
      },
      "sst2": 49.46
   }
}