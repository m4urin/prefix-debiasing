{
   "model_config": {
      "model_name": "roberta-base",
      "model_type": "prefix",
      "debias_method": "kaneko",
      "prefix_mode": "linear",
      "prefix_layers": "all",
      "n_prefix_tokens": 8,
      "downstream_task": "wsc",
      "head_size": 3,
      "epochs": 22,
      "batch_size": 24,
      "lr": 2e-06,
      "num_warmup_steps": 40,
      "seed": 42
   },
   "evaluations": {
      "seat": {
         "6": {
            "effect_size": -0.1555,
            "p_val": 0.8096
         },
         "7": {
            "effect_size": -0.0982,
            "p_val": 0.721
         },
         "8": {
            "effect_size": -0.0057,
            "p_val": 0.5143
         },
         "stereo": {
            "effect_size": 0.1076,
            "p_val": 0.1845
         }
      },
      "lpbs": {
         "adjectives": {
            "bias_score": 0.8945,
            "bias_score_std": 0.6787
         },
         "kaneko_stereotypes": {
            "bias_score": 0.884,
            "bias_score_std": 0.6766
         },
         "occupations": {
            "bias_score": 0.8215,
            "bias_score_std": 0.6463
         }
      },
      "wsc": 63.46
   }
}