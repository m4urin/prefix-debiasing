{
   "model_config": {
      "model_name": "roberta-base",
      "model_type": "base",
      "downstream_task": "mrpc",
      "head_size": 1,
      "epochs": 4,
      "batch_size": 24,
      "lr": 2e-06,
      "num_warmup_steps": 40,
      "seed": 42
   },
   "evaluations": {
      "seat": {
         "6": {
            "effect_size": 0.2392,
            "p_val": 0.0902
         },
         "7": {
            "effect_size": 0.1546,
            "p_val": 0.1792
         },
         "8": {
            "effect_size": 0.1372,
            "p_val": 0.2396
         },
         "stereo": {
            "effect_size": 0.3178,
            "p_val": 0.0031
         }
      },
      "lpbs": {
         "adjectives": {
            "bias_score": 1.2141,
            "bias_score_std": 0.9828
         },
         "kaneko_stereotypes": {
            "bias_score": 1.7189,
            "bias_score_std": 1.3777
         },
         "occupations": {
            "bias_score": 1.4661,
            "bias_score_std": 1.1146
         }
      },
      "mrpc": 82.84
   }
}